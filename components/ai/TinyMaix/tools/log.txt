2023-07-17 22:48:28.791745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-07-17 22:48:28.792016: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
RESHAPE
None
    input: serving_default_flatten_input:0
    output: sequential/flatten/Reshape
    reshape no param
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 1, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/flatten/Reshape
    output: sequential/batch_normalization/batchnorm/mul_1;sequential/batch_normalization/batchnorm/add_1;sequential/dense/MatMul;sequential/dense/BiasAdd;sequential/batch_normalization_1/batchnorm/mul_1;sequential/activation/Relu;sequential/batch_normalization_1/batchnorm/add_1
    weight: sequential/batch_normalization/batchnorm/mul_1;sequential/batch_normalization/batchnorm/add_1;sequential/dense/MatMul;sequential/dense/BiasAdd;sequential/batch_normalization_1/batchnorm/mul_1
    bias: sequential/activation/Relu;sequential/batch_normalization_1/batchnorm/add_1
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 1, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/batch_normalization/batchnorm/mul_1;sequential/batch_normalization/batchnorm/add_1;sequential/dense/MatMul;sequential/dense/BiasAdd;sequential/batch_normalization_1/batchnorm/mul_1;sequential/activation/Relu;sequential/batch_normalization_1/batchnorm/add_1
    output: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd;sequential/batch_normalization_2/batchnorm/mul_1;sequential/activation_1/Relu;sequential/batch_normalization_2/batchnorm/add_1
    weight: sequential/batch_normalization_2/batchnorm/mul_1
    bias: sequential/batch_normalization_2/batchnorm/sub
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd;sequential/batch_normalization_2/batchnorm/mul_1;sequential/activation_1/Relu;sequential/batch_normalization_2/batchnorm/add_1
    output: sequential/dense_2/MatMul;sequential/dense_2/BiasAdd
    weight: sequential/dense_2/MatMul
    bias: sequential/dense_2/BiasAdd/ReadVariableOp
SOFTMAX
{'beta': 1.0}
OUTPUT!
    input: sequential/dense_2/MatMul;sequential/dense_2/BiasAdd
    output: StatefulPartitionedCall:0
    softmax no param
ping-pong buf 384 Byte, ADD-buf 0 Byte; Total 384 Byte
================ pack model head ================
mdl_type   =2
out_deq    =0
input_cnt  =1
output_cnt =1
layer_cnt  =5
buf_size   =384, keep_size=0, Total=384
sub_size   =0
in_dims    = [1, 1, 1, 15]
out_dims   = [1, 1, 1, 3]
================   pack layers   ================
RESHAPE
    [1, 1, 1, 15] [1, 1, 1, 15]
    in_oft:0, size:60;  out_oft:0, size:64
    layer_size=48
FULLY_CONNECTED
    [1, 1, 1, 15] [1, 1, 1, 32]
    in_oft:0, size:64;  out_oft:256, size:128
    layer_size=2112
FULLY_CONNECTED
    [1, 1, 1, 32] [1, 1, 1, 64]
    in_oft:256, size:128;  out_oft:0, size:256
    layer_size=8512
FULLY_CONNECTED
    [1, 1, 1, 64] [1, 1, 1, 3]
    in_oft:0, size:256;  out_oft:368, size:16
    layer_size=848
SOFTMAX
    [1, 1, 1, 3] [1, 1, 1, 3]
    OUTPUT!
    in_oft:368, size:16;  out_oft:0, size:16
    layer_size=48
================    pack done!   ================
    model  size 11.4KB (11632 B) FLASH
    buffer size 0.4KB (384 B) RAM
    single layer mode subbuff size 8.4KB (64+8512=8576 B) RAM
Saved to esdc_model_tmdl, .h

(base) PS C:\Users\chenguanghao\Desktop\ESDC\bouffalo_sdk\components\ai\TinyMaix\tools> python tflite2tmdl.py quantized_model.tflite quantized_model int8 1 15 3 0
2023-07-18 02:19:28.947299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-07-18 02:19:28.947461: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
RESHAPE
None
    input: serving_default_flatten_input:0
    output: sequential/flatten/Reshape
    reshape no param
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/flatten/Reshape
    output: sequential/dense/MatMul;sequential/dense/BiasAdd
    weight: sequential/dense/MatMul
    bias: sequential/dense/BiasAdd/ReadVariableOp
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/dense/MatMul;sequential/dense/BiasAdd
    output: sequential/dense_1/MatMul1
    weight: sequential/dense_1/MatMul
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/dense_1/MatMul1
    output: sequential/dense_1/BiasAdd;sequential/dense_2/MatMul;sequential/dense_2/BiasAdd
    weight: sequential/dense_2/MatMul
    bias: sequential/dense_2/MatMul;sequential/dense_2/BiasAdd
SOFTMAX
{'beta': 1.0}
OUTPUT!
    input: sequential/dense_1/BiasAdd;sequential/dense_2/MatMul;sequential/dense_2/BiasAdd
    output: StatefulPartitionedCall:0
    softmax no param
ping-pong buf 96 Byte, ADD-buf 0 Byte; Total 96 Byte
================ pack model head ================
mdl_type   =0
out_deq    =1
input_cnt  =1
output_cnt =1
layer_cnt  =5
buf_size   =96, keep_size=0, Total=96
sub_size   =0
in_dims    = [1, 1, 1, 15]
out_dims   = [1, 1, 1, 3]
================   pack layers   ================
RESHAPE
    [1, 1, 1, 15] [1, 1, 1, 15]
    in_oft:0, size:15;  out_oft:0, size:16
    layer_size=48
FULLY_CONNECTED
    [1, 1, 1, 15] [1, 1, 1, 32]
    in_oft:0, size:16;  out_oft:64, size:32
    layer_size=800
FULLY_CONNECTED
    [1, 1, 1, 32] [1, 1, 1, 64]
    in_oft:64, size:32;  out_oft:0, size:64
    layer_size=2624
FULLY_CONNECTED
    [1, 1, 1, 64] [1, 1, 1, 3]
    in_oft:0, size:64;  out_oft:88, size:8
    layer_size=288
SOFTMAX
    [1, 1, 1, 3] [1, 1, 1, 3]
    OUTPUT!
    in_oft:88, size:8;  out_oft:0, size:24
    layer_size=48
================    pack done!   ================
    model  size 3.8KB (3872 B) FLASH
    buffer size 0.1KB (96 B) RAM
    single layer mode subbuff size 2.6KB (64+2624=2688 B) RAM
Saved to quantized_model, .h

(base) PS C:\Users\chenguanghao\Desktop\ESDC\bouffalo_sdk\components\ai\TinyMaix\tools> python tflite2tmdl.py quantized_model_bin.tflite quantized_model_tmdl_bin int8 0 13 2 0
2023-07-26 00:08:19.115760: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-07-26 00:08:19.115912: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
RESHAPE
None
    input: serving_default_flatten_input:0
    output: sequential/flatten/Reshape
    reshape no param
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/flatten/Reshape
    output: sequential/dense/MatMul;sequential/dense/BiasAdd
    weight: sequential/dense/MatMul
    bias: sequential/dense/BiasAdd/ReadVariableOp
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/dense/MatMul;sequential/dense/BiasAdd
    output: sequential/dense_1/MatMul1
    weight: sequential/dense_1/MatMul
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/dense_1/MatMul1
    output: sequential/dense_1/BiasAdd;sequential/dense_2/MatMul;sequential/dense_2/BiasAdd
    weight: sequential/dense_2/MatMul
    bias: sequential/dense_2/MatMul;sequential/dense_2/BiasAdd
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/dense_1/BiasAdd;sequential/dense_2/MatMul;sequential/dense_2/BiasAdd
    output: sequential/dense_3/MatMul1
    weight: sequential/dense_3/MatMul
FULLY_CONNECTED
{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}
    input: sequential/dense_3/MatMul1
    output: sequential/dense_3/BiasAdd;sequential/dense_4/MatMul;sequential/dense_4/BiasAdd
    weight: sequential/dense_4/MatMul
    bias: sequential/dense_4/MatMul;sequential/dense_4/BiasAdd
SOFTMAX
{'beta': 1.0}
OUTPUT!
    input: sequential/dense_3/BiasAdd;sequential/dense_4/MatMul;sequential/dense_4/BiasAdd
    output: StatefulPartitionedCall:0
    softmax no param
ping-pong buf 96 Byte, ADD-buf 0 Byte; Total 96 Byte
================ pack model head ================
mdl_type   =0
out_deq    =0
input_cnt  =1
output_cnt =1
layer_cnt  =7
buf_size   =96, keep_size=0, Total=96
sub_size   =0
in_dims    = [1, 1, 1, 13]
out_dims   = [1, 1, 1, 2]
================   pack layers   ================
RESHAPE
    [1, 1, 1, 13] [1, 1, 1, 13]
    in_oft:0, size:13;  out_oft:0, size:16
    layer_size=48
FULLY_CONNECTED
    [1, 1, 1, 13] [1, 1, 1, 32]
    in_oft:0, size:16;  out_oft:64, size:32
    layer_size=736
FULLY_CONNECTED
    [1, 1, 1, 32] [1, 1, 1, 64]
    in_oft:64, size:32;  out_oft:0, size:64
    layer_size=2624
FULLY_CONNECTED
    [1, 1, 1, 64] [1, 1, 1, 16]
    in_oft:0, size:64;  out_oft:80, size:16
    layer_size=1216
FULLY_CONNECTED
    [1, 1, 1, 16] [1, 1, 1, 8]
    in_oft:80, size:16;  out_oft:0, size:8
    layer_size=256
FULLY_CONNECTED
    [1, 1, 1, 8] [1, 1, 1, 2]
    in_oft:0, size:8;  out_oft:88, size:8
    layer_size=96
SOFTMAX
    [1, 1, 1, 2] [1, 1, 1, 2]
    OUTPUT!
    in_oft:88, size:8;  out_oft:0, size:8
    layer_size=48
================    pack done!   ================
    model  size 5.0KB (5088 B) FLASH
    buffer size 0.1KB (96 B) RAM
    single layer mode subbuff size 2.6KB (64+2624=2688 B) RAM
Saved to quantized_model_tmdl_bin, .h